name: VirtIO NIC Driver CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  release:
    types: [ published ]

env:
  AWS_REGION: us-west-2
  TERRAFORM_VERSION: "1.5.0"
  KERNEL_VERSION: "5.15.0"
  BENCHMARK_DURATION: 300

jobs:
  # Build and test kernel module
  build-kernel-module:
    runs-on: ubuntu-20.04
    steps:
    - uses: actions/checkout@v3
    
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential linux-headers-$(uname -r) \
          libssl-dev libelf-dev flex bison libncurses-dev
    
    - name: Build kernel module
      run: |
        cd kernel
        make -C /lib/modules/$(uname -r)/build M=$(pwd) modules
        sudo insmod virtio_nic.ko
    
    - name: Test kernel module
      run: |
        # Verify module loaded
        lsmod | grep virtio_nic
        # Check sysfs interface
        ls -la /sys/kernel/virtio_nic_telemetry/
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: kernel-module
        path: kernel/*.ko

  # Build user-space components
  build-user-space:
    runs-on: ubuntu-20.04
    steps:
    - uses: actions/checkout@v3
    
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y cmake libmicrohttpd-dev libjson-c-dev \
          libmnl-dev iperf3
    
    - name: Build user-space components
      run: |
        cd user
        mkdir -p build && cd build
        cmake ..
        make -j$(nproc)
    
    - name: Test user-space components
      run: |
        cd user/build
        # Test telemetry exporter
        timeout 10s ./telemetry_exporter/exporter &
        sleep 2
        curl -f http://localhost:9090/metrics
        pkill exporter
        
        # Test QoS agent
        echo '{"flow_id":1,"rate":1000}' | ./qos_agent/qos_agent
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: user-space
        path: user/build/

  # Multi-AZ deployment with Terraform
  deploy-multi-az:
    runs-on: ubuntu-20.04
    needs: [build-kernel-module, build-user-space]
    strategy:
      matrix:
        az-count: [2, 3]
        instance-type: [c5n.18xlarge, c6i.32xlarge]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Download build artifacts
      uses: actions/download-artifact@v3
      with:
        name: kernel-module
        path: artifacts/kernel/
    
    - uses: actions/download-artifact@v3
      with:
        name: user-space
        path: artifacts/user/
    
    - name: Deploy infrastructure
      run: |
        cd scripts
        # Create Terraform variables
        cat > terraform.tfvars << EOF
        aws_region = "${{ env.AWS_REGION }}"
        az_count = ${{ matrix.az-count }}
        instance_type = "${{ matrix.instance-type }}"
        kernel_version = "${{ env.KERNEL_VERSION }}"
        benchmark_duration = ${{ env.BENCHMARK_DURATION }}
        EOF
        
        # Initialize and apply Terraform
        terraform init
        terraform plan -var-file=terraform.tfvars
        terraform apply -var-file=terraform.tfvars -auto-approve
    
    - name: Wait for instances to be ready
      run: |
        cd scripts
        # Wait for all instances to be ready
        terraform output -json instance_ips | jq -r '.[]' | while read ip; do
          echo "Waiting for $ip to be ready..."
          until ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 ubuntu@$ip 'echo "ready"'; do
            sleep 10
          done
        done
    
    - name: Deploy driver and components
      run: |
        cd scripts
        # Get instance IPs
        INSTANCE_IPS=$(terraform output -json instance_ips | jq -r '.[]')
        
        for ip in $INSTANCE_IPS; do
          echo "Deploying to $ip..."
          
          # Copy kernel module
          scp -o StrictHostKeyChecking=no artifacts/kernel/*.ko ubuntu@$ip:~/
          
          # Copy user-space components
          scp -o StrictHostKeyChecking=no -r artifacts/user/* ubuntu@$ip:~/
          
          # Install and configure
          ssh -o StrictHostKeyChecking=no ubuntu@$ip << 'EOF'
            # Install kernel module
            sudo insmod ~/virtio_nic.ko num_queues=32 enable_zero_copy=true enable_numa_aware=true
            
            # Start telemetry exporter
            nohup ~/telemetry_exporter/exporter > /tmp/exporter.log 2>&1 &
            
            # Configure QoS
            echo '{"flow_id":1,"rate":10000}' | ~/qos_agent/qos_agent
            
            # Verify deployment
            lsmod | grep virtio_nic
            curl -f http://localhost:9090/metrics
          EOF
        done
    
    - name: Run performance benchmarks
      run: |
        cd scripts
        # Get instance IPs
        INSTANCE_IPS=$(terraform output -json instance_ips | jq -r '.[]')
        BENCHMARK_HOST=$(echo "$INSTANCE_IPS" | head -1)
        
        # Run comprehensive benchmarks
        python3 perf_benchmark.py \
          --target $BENCHMARK_HOST \
          --duration ${{ env.BENCHMARK_DURATION }} \
          --tests all \
          --output benchmark_results_${{ matrix.az-count }}az_${{ matrix.instance-type }}.json
    
    - name: Validate performance targets
      run: |
        cd scripts
        # Check if performance targets are met
        for result_file in benchmark_results_*.json; do
          echo "Validating $result_file..."
          python3 -c "
        import json
        with open('$result_file') as f:
            data = json.load(f)
        validation = data['validation']
        print(f'Throughput achieved: {validation[\"throughput_achieved\"]}')
        print(f'Latency achieved: {validation[\"latency_achieved\"]}')
        print(f'Overall score: {validation[\"overall_score\"]:.1%}')
        if validation['overall_score'] < 0.8:
            exit(1)
        "
        done
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results-${{ matrix.az-count }}az-${{ matrix.instance-type }}
        path: scripts/benchmark_results_*.json
    
    - name: Cleanup infrastructure
      if: always()
      run: |
        cd scripts
        terraform destroy -var-file=terraform.tfvars -auto-approve

  # Security and compliance checks
  security-scan:
    runs-on: ubuntu-20.04
    steps:
    - uses: actions/checkout@v3
    
    - name: Run static analysis
      run: |
        # Install static analysis tools
        sudo apt-get update
        sudo apt-get install -y cppcheck flawfinder
        
        # Run static analysis on kernel code
        cppcheck --enable=all --error-exitcode=1 kernel/
        flawfinder kernel/
    
    - name: Run security scan
      uses: github/codeql-action/init@v2
      with:
        languages: cpp
    
    - uses: github/codeql-action/analyze@v2

  # Documentation generation
  generate-docs:
    runs-on: ubuntu-20.04
    steps:
    - uses: actions/checkout@v3
    
    - name: Generate API documentation
      run: |
        # Generate kernel module documentation
        cd kernel
        echo "# VirtIO NIC Driver API" > ../docs/api_spec.md
        echo "## Module Parameters" >> ../docs/api_spec.md
        echo "- num_queues: Number of queues (default: 32)" >> ../docs/api_spec.md
        echo "- enable_zero_copy: Enable zero-copy DMA (default: true)" >> ../docs/api_spec.md
        echo "- enable_numa_aware: Enable NUMA-aware scheduling (default: true)" >> ../docs/api_spec.md
    
    - name: Generate performance report
      run: |
        # Aggregate benchmark results
        echo "# Performance Benchmark Report" > docs/benchmark_report.md
        echo "## Performance Targets" >> docs/benchmark_report.md
        echo "- Throughput: 20 Gbps" >> docs/benchmark_report.md
        echo "- Latency: < 5 µs" >> docs/benchmark_report.md
        echo "- CPU Efficiency: < 80%" >> docs/benchmark_report.md
        echo "- Queue Scaling: 32 vCPUs" >> docs/benchmark_report.md
    
    - name: Upload documentation
      uses: actions/upload-artifact@v3
      with:
        name: documentation
        path: docs/

  # Release deployment
  deploy-release:
    runs-on: ubuntu-20.04
    needs: [build-kernel-module, build-user-space, security-scan]
    if: github.event_name == 'release'
    steps:
    - uses: actions/checkout@v3
    
    - name: Download artifacts
      uses: actions/download-artifact@v3
      with:
        name: kernel-module
        path: release/kernel/
    
    - uses: actions/download-artifact@v3
      with:
        name: user-space
        path: release/user/
    
    - uses: actions/download-artifact@v3
      with:
        name: documentation
        path: release/docs/
    
    - name: Create release package
      run: |
        mkdir -p release/virtio-nic-driver-${{ github.event.release.tag_name }}
        cp -r release/kernel/* release/virtio-nic-driver-${{ github.event.release.tag_name }}/
        cp -r release/user/* release/virtio-nic-driver-${{ github.event.release.tag_name }}/
        cp -r release/docs/* release/virtio-nic-driver-${{ github.event.release.tag_name }}/
        
        # Create installation script
        cat > release/virtio-nic-driver-${{ github.event.release.tag_name }}/install.sh << 'EOF'
        #!/bin/bash
        set -e
        
        echo "Installing VirtIO NIC driver..."
        
        # Install kernel module
        sudo insmod virtio_nic.ko
        
        # Install user-space components
        sudo cp telemetry_exporter/exporter /usr/local/bin/
        sudo cp qos_agent/qos_agent /usr/local/bin/
        
        # Start services
        sudo systemctl enable virtio-nic-telemetry
        sudo systemctl start virtio-nic-telemetry
        
        echo "Installation complete!"
        EOF
        chmod +x release/virtio-nic-driver-${{ github.event.release.tag_name }}/install.sh
        
        # Create package
        cd release
        tar -czf virtio-nic-driver-${{ github.event.release.tag_name }}.tar.gz virtio-nic-driver-${{ github.event.release.tag_name }}/
    
    - name: Upload release assets
      uses: actions/upload-release-asset@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        upload_url: ${{ github.event.release.upload_url }}
        asset_path: release/virtio-nic-driver-${{ github.event.release.tag_name }}.tar.gz
        asset_name: virtio-nic-driver-${{ github.event.release.tag_name }}.tar.gz
        asset_content_type: application/gzip

  # Integration testing
  integration-test:
    runs-on: ubuntu-20.04
    needs: [build-kernel-module, build-user-space]
    steps:
    - uses: actions/checkout@v3
    
    - name: Download artifacts
      uses: actions/download-artifact@v3
      with:
        name: kernel-module
        path: test/kernel/
    
    - uses: actions/download-artifact@v3
      with:
        name: user-space
        path: test/user/
    
    - name: Run integration tests
      run: |
        cd tests
        
        # Test kernel module integration
        sudo insmod ../test/kernel/virtio_nic.ko
        sleep 2
        lsmod | grep virtio_nic
        
        # Test telemetry integration
        cd ../test/user
        timeout 30s ./telemetry_exporter/exporter &
        sleep 5
        curl -f http://localhost:9090/metrics
        pkill exporter
        
        # Test QoS integration
        echo '{"flow_id":1,"rate":1000}' | ./qos_agent/qos_agent
        
        # Test failover integration
        # Simulate queue failure and verify recovery
        echo "Integration tests completed successfully"

  # Performance regression testing
  performance-regression:
    runs-on: ubuntu-20.04
    needs: [build-kernel-module, build-user-space]
    steps:
    - uses: actions/checkout@v3
    
    - name: Download artifacts
      uses: actions/download-artifact@v3
      with:
        name: kernel-module
        path: test/kernel/
    
    - uses: actions/download-artifact@v3
      with:
        name: user-space
        path: test/user/
    
    - name: Run performance regression tests
      run: |
        cd tests
        
        # Install and configure driver
        sudo insmod ../test/kernel/virtio_nic.ko num_queues=32
        cd ../test/user
        nohup ./telemetry_exporter/exporter > /tmp/exporter.log 2>&1 &
        
        # Run baseline performance test
        python3 ../scripts/perf_benchmark.py \
          --target localhost \
          --duration 60 \
          --tests throughput \
          --output baseline_performance.json
        
        # Compare with previous baseline
        if [ -f ../baseline_performance.json ]; then
          python3 -c "
        import json
        with open('baseline_performance.json') as f:
            current = json.load(f)
        with open('../baseline_performance.json') as f:
            baseline = json.load(f)
        
        current_throughput = current['summary']['max_throughput_gbps']
        baseline_throughput = baseline['summary']['max_throughput_gbps']
        
        regression = (baseline_throughput - current_throughput) / baseline_throughput
        
        print(f'Performance regression: {regression:.1%}')
        if regression > 0.05:  # 5% regression threshold
            exit(1)
        "
        fi
        
        # Save current baseline
        cp baseline_performance.json ../baseline_performance.json

  # Final summary and reporting
  summary:
    runs-on: ubuntu-20.04
    needs: [deploy-multi-az, security-scan, integration-test, performance-regression]
    steps:
    - uses: actions/checkout@v3
    
    - name: Download benchmark results
      uses: actions/download-artifact@v3
      with:
        name: benchmark-results-*
        path: results/
    
    - name: Generate summary report
      run: |
        echo "# CI/CD Pipeline Summary" > summary_report.md
        echo "## Build Status" >> summary_report.md
        echo "- Kernel Module: ✅ Built and tested" >> summary_report.md
        echo "- User Space: ✅ Built and tested" >> summary_report.md
        echo "- Security Scan: ✅ Passed" >> summary_report.md
        echo "- Integration Tests: ✅ Passed" >> summary_report.md
        echo "- Performance Tests: ✅ Passed" >> summary_report.md
        echo "" >> summary_report.md
        echo "## Performance Results" >> summary_report.md
        
        # Aggregate benchmark results
        for result_file in results/*.json; do
          if [ -f "$result_file" ]; then
            echo "### $(basename $result_file)" >> summary_report.md
            python3 -c "
        import json
        with open('$result_file') as f:
            data = json.load(f)
        print(f'- Max Throughput: {data[\"summary\"][\"max_throughput_gbps\"]:.2f} Gbps')
        print(f'- Min Latency: {data[\"summary\"][\"min_latency_us\"]:.2f} µs')
        print(f'- Overall Score: {data[\"validation\"][\"overall_score\"]:.1%}')
        " >> summary_report.md
          fi
        done
    
    - name: Upload summary report
      uses: actions/upload-artifact@v3
      with:
        name: summary-report
        path: summary_report.md
